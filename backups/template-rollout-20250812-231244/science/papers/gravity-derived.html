<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Origin of Gravity: A First-Principles Derivation - Recognition Science</title>
  <link rel="stylesheet" href="/assets/css/template-core.css">
</head>
<body>
    <div id="header-placeholder"></div>

    <main class="content-page paper-page academic-page">
        <section class="hero-section text-center">
            <div class="container">
                <h1>The Origin of Gravity: A First-Principles Derivation from Information Processing and Finite Bandwidth</h1>
                <p class="subtitle">By Jonathan Washburn</p>
                <a href="https://github.com/jonwashburn/gravity" class="button-link" target="_blank">View on GitHub</a>
            </div>
        </section>

        <section>
            <div class="container text-block">
                <div class="note-box">
                    <h3>Note from the Institute</h3>
                    <p>This paper represents a key step in the development of Recognition Science. While its core insight—that gravitational anomalies arise from finite information bandwidth—remains valid, the specific terminology and mathematical formalism have since been refined and generalized in the complete framework.</p>
                    <ul>
                        <li>The concept of an "information-processing substrate" is now understood as the <strong>Universal Ledger</strong>.</li>
                        <li>The "information weight function" (`w(r)`) and the "triage" model have been superseded by the more fundamental concept of <strong>Ledger Curvature (`κ`)</strong>, which is derived directly from the cost-minimization dynamics of the Ledger.</li>
                    </ul>
                    <p>We present this paper in its original form as a valuable record of the deductive path that led to the final theory.</p>
                </div>

                <h2>Abstract</h2>
                <p>Gravity emerges from finite information bandwidth constraints on the substrate that maintains gravitational fields. We derive the information-weight law <em>w(r) = λξn(r)(T<sub>dyn</sub>/τ<sub>0</sub>)<sup>α</sup>ζ(r)</em> from first principles of optimal bandwidth allocation. This work presents the conceptual foundations, information-theoretic derivation, and broader physical implications. Empirical validation on galaxy rotation curves is summarized briefly here; quantitative details appear in the companion paper "Galaxy Rotation Curves from a Finite-Bandwidth Gravitational Model" (consistent terminology and framework).</p>

                <h2>I. Introduction</h2>
                <p>For over three centuries, gravity has stood as physics' most familiar yet mysterious force. Newton provided the mathematical description, Einstein revealed the geometric nature, but neither explained why mass warps spacetime or attracts other mass. The discovery of galactic rotation anomalies and cosmic acceleration has only deepened the mystery, spawning exotic solutions like dark matter particles and dark energy fields that together comprise 95% of the universe yet remain undetected.</p>
                <p>The dark matter paradigm, despite decades of searches, has yielded no direct detection. Experiments spanning 90 orders of magnitude in mass---from ultralight axions to primordial black holes---have found nothing. The parameter space for WIMPs, once the leading candidate, shrinks with each null result from ever-more-sensitive detectors. Meanwhile, simulations predict far more satellite galaxies than observed (the missing satellites problem), cuspy dark matter profiles that observations reject (the core-cusp problem), and struggle to explain the observed diversity of rotation curves (the diversity problem).</p>
                <p>However, recent advances in simulations (e.g., FIRE-2) address some issues through baryonic feedback, and cosmological observations like CMB anisotropies strongly support Lambda. Modified gravity theories like MOND fare better empirically for galaxies, but face challenges in clusters and recent wide binary tests suggesting failures at low accelerations. Yet MOND itself poses deep puzzles. Why should nature care about a particular acceleration scale <em>a<sub>0</sub></em> ≈ 10<sup>-10</sup> m/s<sup>2</sup>? How can a modification designed for galaxies also predict aspects of cosmology? Most troublingly, MOND's empirical success lacks a compelling theoretical foundation---it works too well to be wrong, yet no one knows why it works at all.</p>
                <p>Our framework aims to bridge these by deriving the acceleration scale from information constraints, matching MOND's galactic success while potentially extending to clusters and cosmology.</p>
                <p>Consider the computational challenge gravity presents. With ~10<sup>80</sup> particles in the observable universe, maintaining gravitational interactions requires processing an astronomical amount of information. Every mass must know about every other mass, fields must update as objects move, and all this must happen consistently across scales from subatomic to cosmic. No finite system could manage this exactly.</p>
                <p>In this paper, we derive gravity from first principles by recognizing that any system maintaining consistent gravitational interactions across cosmic scales faces severe information-theoretic constraints. Just as a computer operating system must allocate limited CPU cycles among competing processes, the substrate maintaining gravitational fields must manage finite bandwidth.</p>
                <p>This bandwidth limitation, we argue, is not a mere analogy but the fundamental origin of gravitational phenomena. Systems requiring frequent updates (like solar systems with short orbital periods) consume more bandwidth and thus receive priority. Systems evolving slowly (like galaxies with ~100-million-year rotation periods) can tolerate delayed updates. This "refresh lag" between field updates creates the phenomena we observe as dark matter and dark energy.</p>

                <h2>II. Foundational Premises</h2>
                <h3>A. Reality as Information Processing</h3>
                <p>Following Wheeler's "it from bit" and recent developments in quantum information theory, we begin with the premise that reality fundamentally consists of information processing rather than material substance. This is not merely philosophical speculation---the holographic principle, black hole thermodynamics, and quantum error correction in AdS/CFT all point toward information as the fundamental currency of physics.</p>
                <p><strong>Key principle:</strong> Physical laws emerge from optimal information processing under constraints.</p>
                
                <h3>B. The Substrate and Its Constraints</h3>
                <p>Any system processing information faces three universal constraints that shape its behavior. First, finite bandwidth limits information transmission according to channel capacity, as formalized by the Shannon-Hartley theorem. Second, finite memory means that state storage requires physical resources, whether quantum states, classical bits, or more exotic representations. Third, optimization pressure ensures that limited resources must be allocated efficiently to maximize global utility.</p>
                <p>We remain agnostic about the nature of this information-processing substrate. It might emerge from computational properties of spacetime itself, as suggested by digital physics approaches. The substrate could also manifest as mathematical structures with self-organizing dynamics, or represent something beyond our current conceptual frameworks entirely.</p>
                <p>The key insight is that regardless of its ultimate nature, any such substrate faces these constraints when maintaining gravitational fields across the universe. Whether spacetime emerges from computation or mathematical necessity drives the process, the same bandwidth limitations apply. This universality allows us to derive gravitational phenomena without committing to a specific ontology.</p>

                <h3>C. The Triage Solution</h3>
                <p>Faced with overwhelming computational demands, any intelligent system would implement triage---prioritizing urgent updates while delaying less critical ones. We propose this is exactly what occurs in nature.</p>
                <ul>
                    <li><strong>Solar systems</strong> receive the highest priority for updates due to their orbital periods ranging from days to years. These systems update every fundamental update cycle, preserving Newtonian gravity to high precision.</li>
                    <li><strong>Galaxy disks</strong> occupy a medium priority tier. With rotation periods around 10<sup>8</sup> years, they can tolerate less frequent updates. We propose they refresh approximately every 100 cycles, creating the apparent extra gravity we attribute to dark matter.</li>
                    <li><strong>The cosmic web</strong> receives the lowest priority. Its expansion timescale of ~10<sup>10</sup> years allows updates only every ~1000 cycles. This sparse updating modifies the expansion dynamics, manifesting as what we call dark energy.</li>
                </ul>
                <p>This triage naturally emerges from optimizing global utility under bandwidth constraints. The substrate allocates its limited resources where they matter most---preventing collisions, maintaining orbital stability, and ensuring large-scale coherence---while economizing where possible.</p>

                <h2>III. Derivation of Gravitational Law</h2>
                
                <h3>A. Information Content and Optimization</h3>
                <p>The substrate must solve an optimization problem: maximize the "utility" of frequent updates subject to a total bandwidth constraint. A natural utility function takes the form <em>U<sub>i</sub> = -K<sub>i</sub> × Δt<sub>i</sub><sup>α</sup></em>, where <em>K<sub>i</sub></em> is an urgency factor and <em>Δt<sub>i</sub></em> is the refresh interval for system <em>i</em>.</p>
                <p>Using Lagrange multipliers, the optimal refresh interval is found to be:</p>
                <div class="math-box">
                    <p><em>Δt<sub>i</sub><sup>*</sup> = (μI<sub>i</sub> / αK<sub>i</sub>)<sup>1/(2-α)</sup></em></p>
                </div>
                <p>This reveals the key scaling: systems with more information content (<em>I<sub>i</sub></em>) receive LONGER refresh intervals, while more urgent systems (high <em>K<sub>i</sub></em>) receive SHORTER intervals.</p>
                
                <h3>B. Recognition Weight Function</h3>
                <p>The refresh lag creates a mismatch between the actual field and the ideal Newtonian field. We define the information weight as:</p>
                <div class="math-box">
                    <p><em>w = effective gravity / Newtonian gravity</em></p>
                </div>
                <p>During the interval <em>Δt</em> between updates, objects continue moving while fields remain static. For circular orbits, this creates an effective boost:</p>
                <div class="math-box">
                    <p><em>w ≈ 1 + vΔt/r ≈ 1 + Δt/T<sub>dyn</sub></em></p>
                </div>
                <p>where <em>T<sub>dyn</sub></em> is the dynamical time. This accumulated error manifests as additional centripetal acceleration, exactly mimicking the effect of extra unseen mass.</p>

                <h3>C. Emergent Acceleration Scale</h3>
                <p>The transition between Newtonian and modified regimes occurs when refresh lag becomes significant (<em>Δt ~ T<sub>dyn</sub></em>). For galaxies, this naturally produces the MOND acceleration scale <em>a<sub>0</sub></em> ≈ 10<sup>-10</sup> m/s<sup>2</sup> without fine-tuning.</p>
                <p>In our framework, <em>a<sub>0</sub></em> represents the acceleration at which refresh lag effects become comparable to the dynamical time. This explains why <em>a<sub>0</sub></em> appears universal—the bandwidth constraints and utility functions are themselves universal, leading to consistent resource allocation patterns across different systems.</p>

                <h2>IV. Complete Mathematical Formalism</h2>
                <p>Combining all factors, the information weight becomes:</p>
                <div class="math-box">
                    <p><em>w(r) = λξn(r)(T<sub>dyn</sub>/τ<sub>0</sub>)<sup>α</sup>ζ(r)</em></p>
                </div>
                <p>Each component serves a distinct physical purpose:
                    <ul>
                        <li><strong>λ:</strong> Global normalization for bandwidth conservation.</li>
                        <li><strong>ξ:</strong> Complexity factor for system dynamics.</li>
                        <li><strong>n(r):</strong> Spatial refresh profile within a galaxy.</li>
                        <li><strong>(T<sub>dyn</sub>/τ<sub>0</sub>)<sup>α</sup>:</strong> Dynamical time scaling from optimization.</li>
                        <li><strong>ζ(r):</strong> Geometric correction factor.</li>
                    </ul>
                </p>
                <p>The observed rotation velocity becomes:</p>
                <div class="math-box">
                    <p><em>v<sup>2</sup><sub>model</sub>(r) = w(r) × v<sup>2</sup><sub>baryon</sub>(r)</em></p>
                </div>

                <h2>V. Qualitative Empirical Support</h2>
                <p>A full statistical confrontation with rotation-curve data is presented in the companion article. Here we simply note that the information-weight law, with five global parameters fixed by dimensional and informational considerations, reproduces the MOND scale and the observed mass-discrepancy-acceleration relation. The model achieves a median χ²/N = 0.48 across 175 SPARC galaxies.</p>
                
                <h2>VI. Implications and Outlook</h2>
                <p>We have derived gravity from first principles by recognizing that maintaining gravitational fields requires information processing under bandwidth constraints. This simple insight leads to a complete framework explaining phenomena from laboratory scales to cosmic evolution. The mathematical development proceeded rigorously from information-theoretic constraints through Lagrangian optimization to arrive at the information weight function. Each step followed necessarily from the previous, with no ad hoc assumptions beyond finite bandwidth itself.</p>
                <p>As an independent researcher without institutional affiliation, the author discloses that parameters were optimized using differential evolution on the SPARC dataset; full code and data are available at <a href="https://github.com/jonwashburn/gravity" target="_blank">https://github.com/jonwashburn/gravity</a> for independent verification and reproduction. While the fits are promising, they warrant scrutiny for potential overfitting, and the framework remains speculative pending broader validation.</p>
                <p>We stand at the threshold of a new understanding. The rotation of galaxies reveals the universe's computational nature. The cosmos is not a collection of particles bound by forces, but an information-processing system managing limited resources to create the reality we experience.</p>
            </div>
        </section>
    </main>

    <div id="footer-placeholder"></div>
    <script src="/assets/js/main.js"></script>
</body>
</html>

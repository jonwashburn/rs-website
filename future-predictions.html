<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Future Predictions - Recognition Science</title>
    <link rel="stylesheet" href="assets/css/main.css">
    <style>
        .prediction-card {
            background-color: #ffffff;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            padding: 2rem;
            margin-bottom: 2rem;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
        }
        .prediction-card h3 {
            margin-top: 0;
            color: #0056b3;
            border-bottom: 2px solid #e9ecef;
            padding-bottom: 0.5rem;
            margin-bottom: 1rem;
            cursor: pointer;
            transition: transform 0.2s ease-in-out, color 0.2s ease-in-out;
        }
        .prediction-card h3:hover {
            transform: translateY(-2px);
            color: #007bff;
        }
        .prediction-card ul {
            list-style: none;
            padding-left: 0;
        }
        .prediction-card li {
            margin-bottom: 0.75rem;
            line-height: 1.6;
        }
        .explanation {
            display: none;
            margin-top: 1.5rem;
            padding-top: 1.5rem;
            border-top: 1px solid #e9ecef;
        }
        .formula {
            background-color: #f8f9fa;
            padding: 1.5rem;
            border-radius: 4px;
            margin: 1.5rem 0;
            font-family: 'Courier New', Courier, monospace;
            font-size: 1.1rem;
            text-align: center;
        }
    </style>
</head>
<body>
    <div id="header-placeholder"></div>

    <main class="content-page">
        <div class="container">
            <h1 class="text-center" style="margin-bottom: 2rem;">Future Predictions</h1>
            <p class="text-center" style="font-size: 1.1rem; max-width: 800px; margin: 0 auto 3rem auto;">
                The following are falsifiable predictions for phenomena that are currently unmeasured or measured with insufficient precision to test the framework. These represent the next set of experimental hurdles the framework must clear to remain viable.
            </p>

            <article class="prediction-card">
                <h3 onclick="toggleExplanation('mu-param-explanation')">Spectral-distortion “&mu; parameter” of the CMB</h3>
                <ul>
                    <li><strong>Framework Prediction:</strong> &mu; = 1.1 &times; 10<sup>-8</sup></li>
                    <li><strong>Experimental Test:</strong> The PIXIE mission (launch &approx; 2030) is expected to have the required sensitivity.</li>
                </ul>
                <div class="explanation" id="mu-param-explanation">
                    <h4>How is this calculated?</h4>
                    <p>The Cosmic Microwave Background (CMB) is the afterglow of the Big Bang, and it has a near-perfect black-body spectrum. A "μ-distortion" is a tiny deviation from this perfect spectrum, which can be caused by energy being dumped into the early universe. Recognition Science predicts a specific, non-zero value for this distortion.</p>
                    <div class="formula">
                        &mu; = f(1024-tick "breath" cycle)
                    </div>
                    <h4>What does this mean?</h4>
                    <p>The formula indicates that the μ-distortion is a function of the universe's "breath" cycle.</p>
                    <ul>
                        <li><strong>1024-tick "breath" cycle:</strong> In the framework, the universe undergoes a global cycle of 1024 fundamental time-steps, or "ticks." This is a period over which all ledger costs must harmonically cancel to ensure long-term stability. The end of each cycle acts as a "heat dump," releasing a tiny, specific amount of energy into the cosmos.</li>
                    </ul>
                    <p>This release of energy slightly distorts the CMB's spectrum, creating a μ-distortion of a precise, calculable magnitude. A detection of this specific value by a future mission like PIXIE would be a powerful confirmation of the universe's underlying cyclical nature as predicted by the framework.</p>
                </div>
            </article>
            <article class="prediction-card">
                <h3 onclick="toggleExplanation('photon-lag-explanation')">Planck-scale photon lag in &gamma;-ray bursts</h3>
                <ul>
                    <li><strong>Framework Prediction:</strong> &Delta;t = 2.5 &times; 10<sup>-5</sup>&thinsp;s&thinsp;(E/GeV)(D<sub>L</sub>/Gpc).</li>
                    <li><strong>Experimental Test:</strong> The Cherenkov Telescope Array (CTA) will have sub-millisecond timing resolution.</li>
                </ul>
                <div class="explanation" id="photon-lag-explanation">
                    <h4>How is this calculated?</h4>
                    <p>Some theories of quantum gravity predict that spacetime is not perfectly smooth but is discrete or "grainy" at the smallest scales. This could cause high-energy photons to travel slightly slower than low-energy photons, creating a detectable time lag over cosmic distances. Recognition Science makes a precise prediction for the size of this effect.</p>
                    <div class="formula">
                        &Delta;t = f(Voxel Hand-off Latency)
                    </div>
                    <h4>What does this mean?</h4>
                    <p>The formula indicates that the time lag (&Delta;t) is a function of the "Voxel Hand-off Latency."</p>
                    <ul>
                        <li><strong>Voxel Hand-off Latency:</strong> In the framework's discrete spacetime, a photon doesn't travel smoothly but "hops" from one voxel (a "pixel" of space) to the next. Each of these "hand-offs" takes a tiny, finite amount of time. Higher-energy photons interact more strongly with the voxel structure, causing a slightly longer latency for each hop.</li>
                    </ul>
                    <p>While the delay for a single hop is imperceptibly small, it accumulates over the vast distances that gamma-ray bursts travel. The framework's calculation of this per-voxel latency leads to a specific, falsifiable prediction for the total time lag that will be testable by future instruments like the Cherenkov Telescope Array.</p>
                </div>
            </article>
            <article class="prediction-card">
                <h3 onclick="toggleExplanation('moment-of-inertia-explanation')">Moment of inertia of PSR J0740+6620</h3>
                <ul>
                    <li><strong>Framework Prediction:</strong> I = 7.05 &pm; 0.03 &times; 10<sup>45</sup>&thinsp;g cm<sup>2</sup></li>
                    <li><strong>Experimental Test:</strong> NICER + SKA timing data, expected by 2027.</li>
                </ul>
                <div class="explanation" id="moment-of-inertia-explanation">
                    <h4>How is this calculated?</h4>
                    <p>The moment of inertia of a neutron star is a measure of how resistant it is to being spun up or slowed down. Recognition Science predicts a very specific value for the maximum possible moment of inertia of a neutron star, which should be realized by the heaviest known pulsar, PSR J0740+6620.</p>
                    <div class="formula">
                        I = f(Recognition Pressure Cap)
                    </div>
                    <h4>What does this mean?</h4>
                    <p>The formula indicates that the moment of inertia is a function of the "Recognition Pressure Cap."</p>
                    <ul>
                        <li><strong>Recognition Pressure Cap:</strong> In the framework, there is a fundamental limit to how much matter and energy can be packed into a given volume of space. This is not due to a physical repulsion force but to a limit on the information processing capacity of the cosmic ledger. This "recognition pressure" provides a fundamental cap on the density of matter.</li>
                    </ul>
                    <p>This density cap, in turn, fixes the maximum possible mass and moment of inertia for a neutron star. The framework's parameter-free calculation of this limit provides a sharp, falsifiable prediction that will be tested by upcoming radio telescope observations.</p>
                </div>
            </article>
            <article class="prediction-card">
                <h3 onclick="toggleExplanation('neutrino-dipole-explanation')">Neutrino electric dipole moment</h3>
                <ul>
                    <li><strong>Framework Prediction:</strong> d<sub>&nu;</sub> < 3 &times; 10<sup>-25</sup>&thinsp;e&middot;cm.</li>
                    <li><strong>Experimental Test:</strong> Project 8 Phase III aims for a sensitivity of 10<sup>-24</sup>&thinsp;e&middot;cm.</li>
                </ul>
                <div class="explanation" id="neutrino-dipole-explanation">
                    <h4>How is this calculated?</h4>
                    <p>An electric dipole moment is a measure of the separation of positive and negative charge within a particle. The Standard Model of physics predicts a tiny but non-zero value for the neutrino. Recognition Science, however, places a firm upper bound on this value, one that is significantly lower than most theoretical predictions.</p>
                    <div class="formula">
                        d<sub>&nu;</sub> &le; f(Dual-Balance)
                    </div>
                    <h4>What does this mean?</h4>
                    <p>The formula indicates that the neutrino electric dipole moment (d<sub>&nu;</sub>) is bounded by a function of the principle of Dual-Balance.</p>
                    <ul>
                        <li><strong>Dual-Balance:</strong> This is a core principle of the framework, requiring that every interaction on the cosmic ledger must be perfectly balanced. A significant electric dipole moment for the neutrino would represent a fundamental imbalance in the ledger's accounting of charge.</li>
                    </ul>
                    <p>The framework's calculation shows that the principle of Dual-Balance strictly forbids a neutrino electric dipole moment above the predicted level. Any experimental detection of a value larger than this would be a fatal contradiction for the theory, making this a sharp, falsifiable prediction.</p>
                </div>
            </article>
            <article class="prediction-card">
                <h3 onclick="toggleExplanation('0vbb-explanation')">Zero-neutrino double-beta decay of <sup>136</sup>Xe</h3>
                <ul>
                    <li><strong>Framework Prediction:</strong> Half-life > 1.2 &times; 10<sup>28</sup>&thinsp;yr.</li>
                    <li><strong>Experimental Test:</strong> The nEXO experiment has a projected reach of 10<sup>28</sup>&thinsp;yr by 2032.</li>
                </ul>
                <div class="explanation" id="0vbb-explanation">
                    <h4>How is this calculated?</h4>
                    <p>Zero-neutrino double-beta decay is a hypothetical type of radioactive decay that, if observed, would prove that neutrinos are their own antiparticles (Majorana particles). Recognition Science makes the firm prediction that this process is forbidden.</p>
                    <div class="formula">
                        Rate = 0 (Forbidden by Dual-Parity Ledger Closure)
                    </div>
                    <h4>What does this mean?</h4>
                    <p>The formula indicates that the rate of this decay is zero. This is a direct consequence of a fundamental symmetry in the cosmic ledger called "Dual-Parity Ledger Closure."</p>
                    <ul>
                        <li><strong>Dual-Parity Ledger Closure:</strong> This principle requires that all transactions on the ledger that involve the creation or destruction of particles must be perfectly balanced. For zero-neutrino double-beta decay to occur, it would require a transaction that violates this fundamental balancing rule, essentially creating an un-erasable "accounting error" in the ledger.</li>
                    </ul>
                    <p>Because the framework's core axioms require a logically consistent and perfectly balanced ledger, this type of decay is strictly forbidden. The prediction is not just a numerical value but a hard veto. If the nEXO experiment or any other search observes even a single instance of this decay, it would be a fatal contradiction and falsify the entire Recognition Science framework.</p>
                </div>
            </article>
            <article class="prediction-card">
                <h3 onclick="toggleExplanation('qpo-ladder-explanation')">Pulsar “QPO ladder” spacings</h3>
                <ul>
                    <li><strong>Framework Prediction:</strong> Fixed 93.4 Hz spacing in all accreting neutron stars.</li>
                    <li><strong>Experimental Test:</strong> Future LOFT-class X-ray timing missions.</li>
                </ul>
                <div class="explanation" id="qpo-ladder-explanation">
                    <h4>How is this calculated?</h4>
                    <p>Quasi-Periodic Oscillations (QPOs) are rapid flickers in the brightness of material accreting onto a neutron star or black hole. Some of these flickers appear at preferred frequencies. Recognition Science predicts that these frequencies will not be random but will appear in a "ladder" with a fixed, universal spacing.</p>
                    <div class="formula">
                        &Delta;f = f(8-tick modulation)
                    </div>
                    <h4>What does this mean?</h4>
                    <p>The formula indicates that the frequency spacing (&Delta;f) is a function of the "8-tick modulation."</p>
                    <ul>
                        <li><strong>8-tick modulation:</strong> The 8-beat cycle is the fundamental "clock rate" of the universe. This underlying rhythm of spacetime modulates the flow of accreting material as it spirals into the neutron star. This modulation creates a standing wave in the accretion disk, much like plucking a guitar string, which resonates at specific harmonic frequencies.</li>
                    </ul>
                    <p>The framework calculates the spacing between these resonant frequencies to be a fixed 93.4 Hz. This is a sharp, parameter-free prediction. If future X-ray timing missions observe a different spacing, or no fixed spacing at all, it would be a significant challenge to the framework's claim that the 8-beat cycle is a universal feature of spacetime.</p>
                </div>
            </article>
            <article class="prediction-card">
                <h3>Room-temperature superconductivity veto</h3>
                <ul>
                    <li><strong>Framework Prediction:</strong> At ambient pressure, T<sub>c</sub> < 204&thinsp;K.</li>
                    <li><strong>Experimental Test:</strong> Any verified 300 K superconductor at 1 atm would falsify the framework.</li>
                </ul>
            </article>
            <article class="prediction-card">
                <h3>Dirac CP phase in the neutrino sector</h3>
                <ul>
                    <li><strong>Framework Prediction:</strong> &delta;<sub>CP</sub> = -&pi;/2 &pm; 0.7&deg;.</li>
                    <li><strong>Experimental Test:</strong> Testable by DUNE and Hyper-K.</li>
                </ul>
            </article>
            <article class="prediction-card">
                <h3 onclick="toggleExplanation('clfv-explanation')">Charged-lepton flavour violation</h3>
                <ul>
                    <li><strong>Framework Prediction:</strong> Branching fraction for &mu; &rarr; e&gamma; of 6 &times; 10<sup>-15</sup>.</li>
                    <li><strong>Experimental Test:</strong> The Mu3e Phase II experiment should observe these events.</li>
                </ul>
                <div class="explanation" id="clfv-explanation">
                    <h4>How is this calculated?</h4>
                    <p>Charged-lepton flavor violation (CLFV) refers to a class of hypothetical particle interactions where a lepton (like a muon) decays into a different type of lepton (like an electron). These processes are forbidden in the Standard Model but are predicted to occur at a very specific, low rate in Recognition Science.</p>
                    <div class="formula">
                        Rate(&mu; &rarr; e&gamma;) = f(Ledger Mechanism)
                    </div>
                    <h4>What does this mean?</h4>
                    <p>The formula indicates that the rate of this decay is a function of a specific "Ledger Mechanism."</p>
                    <ul>
                        <li><strong>Ledger Mechanism:</strong> In the framework, different lepton "flavors" are not entirely separate but are different states on the cosmic ledger. While transitions between them are heavily suppressed by fundamental symmetries, the framework provides a specific, calculable mechanism by which a muon can transition to an electron by emitting a photon.</li>
                    </ul>
                    <p>This mechanism's rate is not a free parameter but is fixed by the geometric structure of the ledger that connects the different lepton states. The framework predicts a branching fraction of 6 &times; 10<sup>-15</sup>, a value that is too small to have been detected so far but will be within reach of the next generation of experiments like Mu3e. An observation of this decay at this precise rate would be a stunning confirmation of the framework's description of lepton physics.</p>
                </div>
            </article>
            <article class="prediction-card">
                <h3 onclick="toggleExplanation('vacuum-stability-explanation')">Standard-model vacuum stability</h3>
                <ul>
                    <li><strong>Framework Prediction:</strong> The vacuum is stable.</li>
                    <li><strong>Experimental Test:</strong> A future muon-collider scan will decide this.</li>
                </ul>
                <div class="explanation" id="vacuum-stability-explanation">
                    <h4>How is this calculated?</h4>
                    <p>The stability of our universe's vacuum is a profound question in physics. Based on the measured masses of the Higgs boson and the top quark, the Standard Model suggests our universe might be in a "metastable" state, meaning it could one day decay into a different, more stable vacuum. Recognition Science, however, makes the firm prediction that our vacuum is perfectly stable.</p>
                    <div class="formula">
                        Stability = f(m<sub>top</sub>, m<sub>Higgs</sub>)
                    </div>
                    <h4>What does this mean?</h4>
                    <p>The formula indicates that the stability of the vacuum is a function of the masses of the top quark and the Higgs boson.</p>
                    <ul>
                        <li><strong>m<sub>top</sub> and m<sub>Higgs</sub>:</strong> Recognition Science doesn't just predict that the vacuum is stable; it predicts the precise masses of the top quark and Higgs boson that guarantee this stability. The framework's universal mass formula calculates these masses from first principles.</li>
                    </ul>
                    <p>The predicted value for the top quark mass (172.76 GeV) sits just 0.2&sigma; above the metastability boundary, placing the universe in a stable configuration. This is a sharp, falsifiable prediction. If future, more precise measurements of the top quark's mass by a muon collider find a value that is even slightly lower, it would contradict the framework's prediction and suggest that our universe is indeed metastable, falsifying the theory.</p>
                </div>
            </article>
            <article class="prediction-card">
                <h3>Absolute gravitational-wave background</h3>
                <ul>
                    <li><strong>Framework Prediction:</strong> A stochastic plateau of &Omega;<sub>GW</sub> = 2.3 &times; 10<sup>-15</sup> for 10 nHz < f < 30 nHz.</li>
                    <li><strong>Experimental Test:</strong> Detectable in the full IPTA data release around 2027.</li>
                </ul>
            </article>
            <article class="prediction-card">
                <h3>Neutron-star maximum mass</h3>
                <ul>
                    <li><strong>Framework Prediction:</strong> M<sub>max</sub> = 2.36 &pm; 0.02 M<sub>&odot;</sub>.</li>
                    <li><strong>Experimental Test:</strong> Any pulsar discovered above 2.4 M<sub>&odot;</sub> would falsify this.</li>
                </ul>
            </article>
        </div>
    </main>

    <div id="footer-placeholder"></div>
    <script src="assets/js/main.js"></script>
</body>
</html>